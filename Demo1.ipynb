{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8922827-567d-49e7-8e7d-c5e8caecaaca",
   "metadata": {},
   "source": [
    "# Real Time Object Detection Demo with Machine Learning Development Environment on FMV images\n",
    "\n",
    "### AUSA 2023 Demo\n",
    "<img src='img/fmv2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cae7328-4e9e-403d-a471-03dbddb591e3",
   "metadata": {},
   "source": [
    "## Running pretrained model\n",
    "\n",
    "Here we will show a pretrained model running on Drone Footage. Notice how there is a lot of flickering in model predictions, and it is not capable of counting vehicles in the scene. This is because the model was pretrained on a publically available dataset of objects in mobile images (called the COCO Dataset). \n",
    "\n",
    "The model was not finetuned for FMV footage nor this domain. We will see the result of finetuning a model for FMV footage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a2c017-73e1-44f5-b728-b0a6035ad3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify', or 'pose'.\n",
      "Ultralytics YOLOv8.0.104 üöÄ Python-3.10.12 torch-1.13.1+cu117 CUDA:0 (Tesla T4, 15110MiB)\n",
      "Loading yolov8l.engine for TensorRT inference...\n",
      "[10/24/2023-12:12:49] [TRT] [I] [MemUsageChange] Init CUDA: CPU +311, GPU +0, now: CPU 414, GPU 7033 (MiB)\n",
      "[10/24/2023-12:12:49] [TRT] [I] Loaded engine size: 181 MiB\n",
      "[10/24/2023-12:12:50] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +630, GPU +292, now: CPU 1260, GPU 7509 (MiB)\n",
      "[10/24/2023-12:12:50] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
      "[10/24/2023-12:12:50] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +32, now: CPU 1079, GPU 7509 (MiB)\n",
      "[10/24/2023-12:12:50] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/psdcadmin/miniconda3/envs/det/bin/yolo\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('ultralytics', 'console_scripts', 'yolo')())\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/cfg/__init__.py\", line 394, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "  File \"/home/psdcadmin/miniconda3/envs/det/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/model.py\", line 253, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/predictor.py\", line 189, in predict_cli\n",
      "    for _ in gen:  # running CLI inference without accumulating any outputs (do not modify)\n",
      "  File \"/home/psdcadmin/miniconda3/envs/det/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 64, in generator_context\n",
      "    response = gen.send(request)\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/predictor.py\", line 267, in stream_inference\n",
      "    self.save_preds(vid_cap, i, str(self.save_dir / p.name))\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/predictor.py\", line 349, in save_preds\n",
      "    self.vid_writer[idx].write(im0)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash run_pretrained_model.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a74ee7-e1af-4f6a-8be9-374bcd4a8680",
   "metadata": {},
   "source": [
    "# How our model performs after finetuning\n",
    "\n",
    "Here we will see how our model performance improves after finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ad1b1c-328f-4549-bab0-7df08ecdfde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify', or 'pose'.\n",
      "Ultralytics YOLOv8.0.104 üöÄ Python-3.10.12 torch-1.13.1+cu117 CUDA:0 (Tesla T4, 15110MiB)\n",
      "Loading exported_weights/best.engine for TensorRT inference...\n",
      "[10/24/2023-12:13:14] [TRT] [I] [MemUsageChange] Init CUDA: CPU +311, GPU +0, now: CPU 414, GPU 8313 (MiB)\n",
      "[10/24/2023-12:13:14] [TRT] [I] Loaded engine size: 181 MiB\n",
      "[10/24/2023-12:13:15] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +630, GPU +292, now: CPU 1260, GPU 8789 (MiB)\n",
      "[10/24/2023-12:13:15] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
      "[10/24/2023-12:13:15] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +32, now: CPU 1079, GPU 8789 (MiB)\n",
      "[10/24/2023-12:13:15] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/psdcadmin/miniconda3/envs/det/bin/yolo\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('ultralytics', 'console_scripts', 'yolo')())\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/cfg/__init__.py\", line 394, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "  File \"/home/psdcadmin/miniconda3/envs/det/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/model.py\", line 253, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/predictor.py\", line 189, in predict_cli\n",
      "    for _ in gen:  # running CLI inference without accumulating any outputs (do not modify)\n",
      "  File \"/home/psdcadmin/miniconda3/envs/det/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 64, in generator_context\n",
      "    response = gen.send(request)\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/predictor.py\", line 264, in stream_inference\n",
      "    self.show(p,inf_speed)\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/predictor.py\", line 328, in show\n",
      "    cv2.waitKey(500 if self.batch[3].startswith('image') else 1)  # 1 millisecond\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#!bash export_and_run_trained_model.sh\n",
    "!bash run_trained_model.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d594efb-7a69-42ce-8b9c-8d84a264ce52",
   "metadata": {},
   "source": [
    "# Finetune Model on Determined\n",
    "Here we will how how we used The Machine Learning Development Environment (Developed by HPE) to finetune our realtime object detection model for FMV footage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "682c534c-6de8-439d-8f44-014d06d402eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from determined.experimental import client as det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef1c4e-72b8-4ba5-a37a-fce288714452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing files to send to master... 10.3MB and 77 files\n",
      "started experiment 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for Experiment 98 to complete. Elapsed 1.0 minutes\n",
      "Waiting for Experiment 98 to complete. Elapsed 2.0 minutes\n"
     ]
    }
   ],
   "source": [
    "# !det experiment create -f run-fmv.yaml . \n",
    "exp = det.create_experiment(config=\"./configs/run-fmv.yaml\", model_dir=\"./\")\n",
    "print(f\"started experiment {exp.id}\")\n",
    "\n",
    "# Wait for experiment to complete and print exit status\n",
    "exit_status = exp.wait()\n",
    "print(f\"experiment completed with status {exit_status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77794219-927e-41db-b246-2efbdc674bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /home/psdcadmin/Documents/andrew/workdir/yolov8-loop-test/runs/detect/ -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf6eb1-22e8-486e-811a-e5530fce57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Miscellaneous\n",
    "# !cp  predictor.py /home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/predictor.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
