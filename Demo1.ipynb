{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8922827-567d-49e7-8e7d-c5e8caecaaca",
   "metadata": {},
   "source": [
    "# Real Time Object Detection Demo with Machine Learning Development Environment on FMV images\n",
    "\n",
    "### AUSA 2023 Demo\n",
    "<img src='img/fmv2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cae7328-4e9e-403d-a471-03dbddb591e3",
   "metadata": {},
   "source": [
    "## Running pretrained model\n",
    "\n",
    "Here we will show a pretrained model running on Drone Footage. Notice how there is a lot of flickering in model predictions, and it is not capable of counting vehicles in the scene. This is because the model was pretrained on a publically available dataset of objects in mobile images (called the COCO Dataset). \n",
    "\n",
    "The model was not finetuned for FMV footage nor this domain. We will see the result of finetuning a model for FMV footage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a2c017-73e1-44f5-b728-b0a6035ad3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify', or 'pose'.\n",
      "Ultralytics YOLOv8.0.104 üöÄ Python-3.10.12 torch-1.13.1+cu117 CUDA:0 (NVIDIA A2, 14831MiB)\n",
      "Loading yolov8l.engine for TensorRT inference...\n",
      "[10/03/2023-15:39:38] [TRT] [I] [MemUsageChange] Init CUDA: CPU +328, GPU +0, now: CPU 431, GPU 191 (MiB)\n",
      "[10/03/2023-15:39:38] [TRT] [I] Loaded engine size: 173 MiB\n",
      "[10/03/2023-15:39:39] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +979, GPU +444, now: CPU 1619, GPU 809 (MiB)\n",
      "[10/03/2023-15:39:39] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
      "[10/03/2023-15:39:39] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +34, now: CPU 1446, GPU 809 (MiB)\n",
      "[10/03/2023-15:39:39] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/psdcadmin/miniconda3/envs/det/bin/yolo\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('ultralytics', 'console_scripts', 'yolo')())\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/cfg/__init__.py\", line 394, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "  File \"/home/psdcadmin/miniconda3/envs/det/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/model.py\", line 253, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/predictor.py\", line 189, in predict_cli\n",
      "    for _ in gen:  # running CLI inference without accumulating any outputs (do not modify)\n",
      "  File \"/home/psdcadmin/miniconda3/envs/det/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 64, in generator_context\n",
      "    response = gen.send(request)\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/predictor.py\", line 240, in stream_inference\n",
      "    preds = self.model(im, augment=self.args.augment, visualize=visualize)\n",
      "  File \"/home/psdcadmin/miniconda3/envs/det/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/nn/autobackend.py\", line 338, in forward\n",
      "    self.context.execute_v2(list(self.binding_addrs.values()))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash run_pretrained_model.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a74ee7-e1af-4f6a-8be9-374bcd4a8680",
   "metadata": {},
   "source": [
    "# How our model performs after finetuning\n",
    "\n",
    "Here we will see how our model performance improves after finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ad1b1c-328f-4549-bab0-7df08ecdfde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify', or 'pose'.\n",
      "Ultralytics YOLOv8.0.104 üöÄ Python-3.10.12 torch-1.13.1+cu117 CUDA:0 (NVIDIA A2, 14831MiB)\n",
      "Loading exported_weights/best.engine for TensorRT inference...\n",
      "[10/03/2023-15:40:01] [TRT] [I] [MemUsageChange] Init CUDA: CPU +328, GPU +0, now: CPU 431, GPU 191 (MiB)\n",
      "[10/03/2023-15:40:02] [TRT] [I] Loaded engine size: 173 MiB\n",
      "[10/03/2023-15:40:03] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +979, GPU +444, now: CPU 1619, GPU 809 (MiB)\n",
      "[10/03/2023-15:40:03] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
      "[10/03/2023-15:40:03] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +34, now: CPU 1446, GPU 809 (MiB)\n",
      "[10/03/2023-15:40:03] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/psdcadmin/miniconda3/envs/det/bin/yolo\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('ultralytics', 'console_scripts', 'yolo')())\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/cfg/__init__.py\", line 394, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "  File \"/home/psdcadmin/miniconda3/envs/det/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/model.py\", line 253, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/predictor.py\", line 189, in predict_cli\n",
      "    for _ in gen:  # running CLI inference without accumulating any outputs (do not modify)\n",
      "  File \"/home/psdcadmin/miniconda3/envs/det/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 64, in generator_context\n",
      "    response = gen.send(request)\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/predictor.py\", line 267, in stream_inference\n",
      "    self.save_preds(vid_cap, i, str(self.save_dir / p.name))\n",
      "  File \"/home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/predictor.py\", line 349, in save_preds\n",
      "    self.vid_writer[idx].write(im0)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#!bash export_and_run_trained_model.sh\n",
    "!bash run_trained_model.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d594efb-7a69-42ce-8b9c-8d84a264ce52",
   "metadata": {},
   "source": [
    "# Finetune Model on Determined\n",
    "Here we will how how we used The Machine Learning Development Environment (Developed by HPE) to finetune our realtime object detection model for FMV footage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c534c-6de8-439d-8f44-014d06d402eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from determined.experimental import client as det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef1c4e-72b8-4ba5-a37a-fce288714452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !det experiment create -f run-fmv.yaml . \n",
    "exp = det.create_experiment(config=\"./configs/run-fmv.yaml\", model_dir=\"./\")\n",
    "print(f\"started experiment {exp.id}\")\n",
    "\n",
    "# Wait for experiment to complete and print exit status\n",
    "exit_status = exp.wait()\n",
    "print(f\"experiment completed with status {exit_status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77794219-927e-41db-b246-2efbdc674bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /home/psdcadmin/Documents/andrew/workdir/yolov8-loop-test/runs/detect/ -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf6eb1-22e8-486e-811a-e5530fce57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Miscellaneous\n",
    "# !cp  predictor.py /home/psdcadmin/Documents/andrew/yolov8-loop-test/ultralytics/yolo/engine/predictor.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
